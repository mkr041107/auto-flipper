{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE1BHRAe1xPq"
      },
      "source": [
        "# Install the New Worker- No more BETA!!\n",
        "### Remember to first set your API KEY and worker name\n",
        "#### You can serve different models, simply change the name in models_to_load to match the model you want, you can check either https://aqualxx.github.io/stable-ui/workers, in the models tab, or https://tinybots.net/artbot/info/models, or https://aihorde.sitew3.com/ also in the models tab (this one also includes text gen models); just copy paste the name (it's set to Deliberate by default)\n",
        "#### You can also change max_power and see how high you can go, it's set to 20 by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRGcHP39Rgy5"
      },
      "outputs": [],
      "source": [
        "# @title ## Only to obtain the models names from the horde. If you want it, tick the checkbox here and run this cell. It does nothing for the worker, it will simply print a list of all the models (Outdated, pending){ display-mode: \"form\" }\n",
        "get_models = False # @param {type:\"boolean\"}\n",
        "\n",
        "if (get_models):\n",
        "\n",
        "  !wget -q -O /content/stable_diffusion.json https://raw.githubusercontent.com/Haidra-Org/AI-Horde-image-model-reference/main/stable_diffusion.json\n",
        "\n",
        "  with open(\"/content/stable_diffusion.json\", 'r') as file:\n",
        "      lines = file.readlines()\n",
        "\n",
        "  delete_name = '        \"name\": '\n",
        "  delete_enter = '\\n'\n",
        "  model_list = []\n",
        "\n",
        "  for i, line in enumerate(lines):\n",
        "      if delete_name in line:\n",
        "          #print(f\"{line.replace(delete_name, '').replace(delete_enter,'')}\")\n",
        "          #model_list.append = [f\"{line.replace(delete_name, '').replace(delete_enter,'')}\"]\n",
        "          model_list.append(line.replace(delete_name, '').replace(delete_enter,''))\n",
        "\n",
        "  model_list.sort()  # Sort the model_list in alphabetical order\n",
        "\n",
        "  #print(model_list)\n",
        "  print(' '.join(model_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFSwvr-7Rgy7"
      },
      "outputs": [],
      "source": [
        "# @title # Simple Timer AND Clearscreen functions { display-mode: \"form\" }\n",
        "from IPython.display import Javascript\n",
        "\n",
        "# JavaScript function to clearscreen\n",
        "js_code = \"\"\"\n",
        "function clearScreen() {\n",
        "  document.body.innerHTML = \"\";\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# JavaScript functions to show timer\n",
        "js_code_2 = \"\"\"let startTime = new Date().getTime(); // Variable to store the start time\n",
        "\n",
        "function formatTime(seconds) {\n",
        "  const hours = Math.floor(seconds / 3600);\n",
        "  const minutes = Math.floor((seconds % 3600) / 60);\n",
        "  const remainingSeconds = seconds % 60;\n",
        "  return `${hours} hours, ${minutes} minutes, ${remainingSeconds} seconds`;\n",
        "}\n",
        "\n",
        "function updateTime() {\n",
        "  const currentTime = new Date().getTime();\n",
        "  const elapsedSeconds = Math.floor((currentTime - startTime) / 1000);\n",
        "  const formattedTime = formatTime(elapsedSeconds);\n",
        "  document.body.innerHTML = formattedTime;\n",
        "}\"\"\"\n",
        "\n",
        "# Set the interval for the function to run\n",
        "interval = \"1000\"\n",
        "\n",
        "# Display the JavaScript code in the cell\n",
        "display(Javascript(js_code_2 + f\"setInterval(updateTime, {interval})\"))\n",
        "\n",
        "def python_clearscreen_now():\n",
        "    display(Javascript(js_code + \"clearScreen()\"))\n",
        "\n",
        "def python_clearscreen_interval(interval):\n",
        "    display(Javascript(js_code + f\"setInterval(clearScreen, {interval})\"))\n",
        "\n",
        "\n",
        "\n",
        "# Function to clear outputs using Python's threads\n",
        "\n",
        "import threading\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def clear_output_periodically(interval):\n",
        "  \"\"\"\n",
        "  Clears the output cell periodically until the stop_thread flag is set.\n",
        "\n",
        "  Args:\n",
        "    interval: The interval in seconds between clearing the output.\n",
        "  \"\"\"\n",
        "  global stop_thread\n",
        "  while not stop_thread:\n",
        "    clear_output(wait=True)\n",
        "    time.sleep(interval)\n",
        "\n",
        "stop_thread = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T23:06:35.113455Z",
          "iopub.status.busy": "2023-10-20T23:06:35.112701Z"
        },
        "id": "qHYIcsqJ1xPs",
        "scrolled": true,
        "trusted": true,
        "outputId": "fe18cfd5-dc47-4a2b-f44d-3532d2f4b69c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: [\"ICBINP - I Can't Believe It's Not Photography\"]\n",
            "bridgeData.yaml file not found. Proceed to install the worker.\n"
          ]
        }
      ],
      "source": [
        "# @title 0.- This cell will set the variables and rerun the worker if you stopped it, but only if everything else was installed already { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "\n",
        "#### For now, THESE are the only variables that we care about\n",
        "worker_name = \"mkrussell411\" #@param {type:\"string\"}\n",
        "api_key = \"KhfL5RPd0h451ZhNSGk8kw\" #@param {type:\"string\"}\n",
        "civitai_token = \"cae554bcc138d97a9323856c2dee1158\" #@param {type:\"string\"}\n",
        "max_power = 20  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "selected_models = []\n",
        "#@markdown  ### Select what model(s) to host\n",
        "#@markdown  Recommended models, (bypasses the \"all models\" selector below when set)\n",
        "recommended_model1 = \"ICBINP - I Can't Believe It's Not Photography\" # @param [\"None\", \"ICBINP - I Can't Believe It's Not Photography\", \"Anything Diffusion\", \"Deliberate\", \"Dreamshaper\", \"BB95 Furry Mix\", \"Hentai Diffusion\", \"Rev Animated\", \"AlbedoBase XL (SDXL)\", \"Fustercluck\", \"ICBINP XL\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Juggernaut XL\", \"Pony Diffusion XL\", \"DreamShaper XL\", \"Cheyenne\", \"Unstable Diffusers XL\", \"Stable Cascade 1.0\"]\n",
        "recommended_model2 = \"None\" # @param [\"None\", \"ICBINP - I Can't Believe It's Not Photography\", \"Anything Diffusion\", \"Deliberate\", \"Dreamshaper\", \"BB95 Furry Mix\", \"Hentai Diffusion\", \"Rev Animated\", \"AlbedoBase XL (SDXL)\", \"Fustercluck\", \"ICBINP XL\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Juggernaut XL\", \"Pony Diffusion XL\", \"DreamShaper XL\", \"Cheyenne\", \"Unstable Diffusers XL\", \"Stable Cascade 1.0\"]\n",
        "\n",
        "#@markdown List of all models\n",
        "model1 = \"Anything Diffusion\" # @param [\"3DKX\", \"526Mix-Animated\", \"A-Zovya RPG Inpainting\", \"ACertainThing\", \"AIO Pixel Art\", \"Abyss OrangeMix\", \"AbyssOrangeMix-AfterDark\", \"AlbedoBase XL (SDXL)\", \"Analog Diffusion\", \"Analog Madness\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Anime Pencil Diffusion\", \"AnyLoRA\", \"Anygen\", \"Anything Diffusion Inpainting\", \"Anything Diffusion\", \"Anything v3\", \"Anything v5\", \"App Icon Diffusion\", \"Art Of Mtg\", \"Aurora\", \"BB95 Furry Mix\", \"BPModel\", \"BRA\", \"Babes\", \"BweshMix\", \"CamelliaMix 2.5D\", \"Cetus-Mix\", \"Char\", \"CharHelper\", \"Cheese Daddys Landscape Mix\", \"Cheyenne\", \"ChilloutMix\", \"ChromaV5\", \"Classic Animation Diffusion\", \"Colorful\", \"Comic-Diffusion\", \"Counterfeit\", \"CyberRealistic\", \"CyriousMix\", \"DGSpitzer Art Diffusion\", \"Dan Mumford Style\", \"Dark Sushi Mix\", \"Dark Victorian Diffusion\", \"Deliberate 3.0\", \"Deliberate Inpainting\", \"Deliberate\", \"Disco Elysium\", \"Disney Pixar Cartoon Type A\", \"DnD Item\", \"DnD Map Generator\", \"Double Exposure Diffusion\", \"DreamLikeSamKuvshinov\", \"DreamShaper Inpainting\", \"DreamShaper XL\", \"Dreamlike Diffusion\", \"Dreamlike Photoreal\", \"Dreamshaper\", \"DucHaiten Classic Anime\", \"DucHaiten\", \"Dungeons and Diffusion\", \"Dungeons n Waifus\", \"Edge Of Realism\", \"Eimis Anime Diffusion\", \"Elldreth's Lucid Mix\", \"Elysium Anime\", \"Epic Diffusion Inpainting\", \"Epic Diffusion\", \"Ether Real Mix\", \"ExpMix Line\", \"Experience\", \"FaeTastic\", \"Fantasy Card Diffusion\", \"Fluffusion\", \"Funko Diffusion\", \"Furry Epoch\", \"Fustercluck\", \"GTA5 Artwork Diffusion\", \"Galena Redux\", \"Ghibli Diffusion\", \"GhostMix\", \"GorynichMix\", \"Grapefruit Hentai\", \"Graphic-Art\", \"GuFeng\", \"GuoFeng\", \"HASDX\", \"HRL\", \"Hassaku\", \"Hassanblend\", \"Healy's Anime Blend\", \"Henmix Real\", \"Hentai Diffusion\", \"ICBINP - I Can't Believe It's Not Photography\", \"ICBINP XL\", \"Illuminati Diffusion\", \"Inkpunk Diffusion\", \"JWST Deep Space Diffusion\", \"Jim Eidomode\", \"JoMad Diffusion\", \"Juggernaut XL\", \"Kenshi\", \"Laolei New Berry Protogen Mix\", \"Lawlas's yiff mix\", \"Liberty\", \"Lyriel\", \"Mega Merge Diffusion\", \"MeinaMix\", \"Microcritters\", \"Microworlds\", \"Midjourney PaintArt\", \"Mistoon Amethyst\", \"ModernArt Diffusion\", \"Moedel\", \"MoistMix\", \"MoonMix Fantasy\", \"Movie Diffusion\", \"Neurogen\", \"NeverEnding Dream\", \"Nitro Diffusion\", \"OpenJourney Diffusion\", \"Openniji\", \"PFG\", \"PPP\", \"Papercut Diffusion\", \"Pastel Mix\", \"Perfect World\", \"Poison\", \"Pokemon3D\", \"Pony Diffusion XL\", \"PortraitPlus\", \"Pretty 2.5D\", \"Project Unreal Engine 5\", \"ProtoGen\", \"Protogen Anime\", \"Protogen Infinity\", \"Pulp Vector Art\", \"RPG\", \"Ranma Diffusion\", \"Real Dos Mix\", \"RealBiter\", \"Realisian\", \"Realism Engine\", \"Realistic Vision Inpainting\", \"Realistic Vision\", \"Reliberate\", \"Rev Animated\", \"Robo-Diffusion\", \"SD-Silicon\", \"SDXL 1.0\", \"Samaritan 3d Cartoon\", \"Sci-Fi Diffusion\", \"Seek.art MEGA\", \"Something\", \"Stable Cascade 1.0\", \"SweetBoys 2D\", \"ToonYou\", \"Trinart Characters\", \"Tron Legacy Diffusion\", \"UMI Olympus\", \"URPM\", \"Uhmami\", \"Ultraskin\", \"Unstable Diffusers XL\", \"Unstable Ink Dream\", \"Vector Art\", \"VinteProtogenMix\", \"Western Animation Diffusion\", \"Woop-Woop Photo\", \"Yiffy\", \"Zack3D\", \"Zeipher Female Model\", \"iCoMix Inpainting\", \"iCoMix\", \"majicMIX realistic\", \"stable_diffusion\", \"stable_diffusion_2.1\", \"stable_diffusion_inpainting\", \"vectorartz\", \"waifu_diffusion\"]\n",
        "model2 = \"None\" # @param [\"None\", \"3DKX\", \"526Mix-Animated\", \"A-Zovya RPG Inpainting\", \"ACertainThing\", \"AIO Pixel Art\", \"Abyss OrangeMix\", \"AbyssOrangeMix-AfterDark\", \"AlbedoBase XL (SDXL)\", \"Analog Diffusion\", \"Analog Madness\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Anime Pencil Diffusion\", \"AnyLoRA\", \"Anygen\", \"Anything Diffusion Inpainting\", \"Anything Diffusion\", \"Anything v3\", \"Anything v5\", \"App Icon Diffusion\", \"Art Of Mtg\", \"Aurora\", \"BB95 Furry Mix\", \"BPModel\", \"BRA\", \"Babes\", \"BweshMix\", \"CamelliaMix 2.5D\", \"Cetus-Mix\", \"Char\", \"CharHelper\", \"Cheese Daddys Landscape Mix\", \"Cheyenne\", \"ChilloutMix\", \"ChromaV5\", \"Classic Animation Diffusion\", \"Colorful\", \"Comic-Diffusion\", \"Counterfeit\", \"CyberRealistic\", \"CyriousMix\", \"DGSpitzer Art Diffusion\", \"Dan Mumford Style\", \"Dark Sushi Mix\", \"Dark Victorian Diffusion\", \"Deliberate 3.0\", \"Deliberate Inpainting\", \"Deliberate\", \"Disco Elysium\", \"Disney Pixar Cartoon Type A\", \"DnD Item\", \"DnD Map Generator\", \"Double Exposure Diffusion\", \"DreamLikeSamKuvshinov\", \"DreamShaper Inpainting\", \"DreamShaper XL\", \"Dreamlike Diffusion\", \"Dreamlike Photoreal\", \"Dreamshaper\", \"DucHaiten Classic Anime\", \"DucHaiten\", \"Dungeons and Diffusion\", \"Dungeons n Waifus\", \"Edge Of Realism\", \"Eimis Anime Diffusion\", \"Elldreth's Lucid Mix\", \"Elysium Anime\", \"Epic Diffusion Inpainting\", \"Epic Diffusion\", \"Ether Real Mix\", \"ExpMix Line\", \"Experience\", \"FaeTastic\", \"Fantasy Card Diffusion\", \"Fluffusion\", \"Funko Diffusion\", \"Furry Epoch\", \"Fustercluck\", \"GTA5 Artwork Diffusion\", \"Galena Redux\", \"Ghibli Diffusion\", \"GhostMix\", \"GorynichMix\", \"Grapefruit Hentai\", \"Graphic-Art\", \"GuFeng\", \"GuoFeng\", \"HASDX\", \"HRL\", \"Hassaku\", \"Hassanblend\", \"Healy's Anime Blend\", \"Henmix Real\", \"Hentai Diffusion\", \"ICBINP - I Can't Believe It's Not Photography\", \"ICBINP XL\", \"Illuminati Diffusion\", \"Inkpunk Diffusion\", \"JWST Deep Space Diffusion\", \"Jim Eidomode\", \"JoMad Diffusion\", \"Juggernaut XL\", \"Kenshi\", \"Laolei New Berry Protogen Mix\", \"Lawlas's yiff mix\", \"Liberty\", \"Lyriel\", \"Mega Merge Diffusion\", \"MeinaMix\", \"Microcritters\", \"Microworlds\", \"Midjourney PaintArt\", \"Mistoon Amethyst\", \"ModernArt Diffusion\", \"Moedel\", \"MoistMix\", \"MoonMix Fantasy\", \"Movie Diffusion\", \"Neurogen\", \"NeverEnding Dream\", \"Nitro Diffusion\", \"OpenJourney Diffusion\", \"Openniji\", \"PFG\", \"PPP\", \"Papercut Diffusion\", \"Pastel Mix\", \"Perfect World\", \"Poison\", \"Pokemon3D\", \"Pony Diffusion XL\", \"PortraitPlus\", \"Pretty 2.5D\", \"Project Unreal Engine 5\", \"ProtoGen\", \"Protogen Anime\", \"Protogen Infinity\", \"Pulp Vector Art\", \"RPG\", \"Ranma Diffusion\", \"Real Dos Mix\", \"RealBiter\", \"Realisian\", \"Realism Engine\", \"Realistic Vision Inpainting\", \"Realistic Vision\", \"Reliberate\", \"Rev Animated\", \"Robo-Diffusion\", \"SD-Silicon\", \"SDXL 1.0\", \"Samaritan 3d Cartoon\", \"Sci-Fi Diffusion\", \"Seek.art MEGA\", \"Something\", \"Stable Cascade 1.0\", \"SweetBoys 2D\", \"ToonYou\", \"Trinart Characters\", \"Tron Legacy Diffusion\", \"UMI Olympus\", \"URPM\", \"Uhmami\", \"Ultraskin\", \"Unstable Diffusers XL\", \"Unstable Ink Dream\", \"Vector Art\", \"VinteProtogenMix\", \"Western Animation Diffusion\", \"Woop-Woop Photo\", \"Yiffy\", \"Zack3D\", \"Zeipher Female Model\", \"iCoMix Inpainting\", \"iCoMix\", \"majicMIX realistic\", \"stable_diffusion\", \"stable_diffusion_2.1\", \"stable_diffusion_inpainting\", \"vectorartz\", \"waifu_diffusion\"]\n",
        "#@markdown Because Colab has low RAM, it is not recommended to run more than 1 model or any of the SDXL models, but you can certainly try (if you do, you might want to set queue size to 0, it will certainly let you run any number of SD 1.5 models, provided you have the disk space for them and you don't mind the long download time and the loading times between models when the worker is actually running)\n",
        "\n",
        "if (recommended_model1 != \"None\"):\n",
        "    selected_models.append(recommended_model1)\n",
        "else:\n",
        "    selected_models.append(model1)\n",
        "\n",
        "if (recommended_model2 != \"None\"):\n",
        "    selected_models.append(recommended_model2)\n",
        "else:\n",
        "    if (model2 != \"None\"):\n",
        "        selected_models.append(model2)\n",
        "\n",
        "\n",
        "# I'm leaving this next line in case you want to set more than 2 models or whatever weird thing you want\n",
        "# simply uncomment it and it will ignore the selections above.\n",
        "# It is set the models I run when I set it to more than 1, but you can change it to whatever you want\n",
        "#selected_models = [\"ICBINP - I Can't Believe It's Not Photography\", \"Deliberate\", \"Anything Diffusion\", \"Dreamshaper\"]\n",
        "\n",
        "###\n",
        "#@markdown ---\n",
        "#@markdown ### Models not supported by the Horde\n",
        "\n",
        "outside_model = False #@param {type:\"boolean\"}\n",
        "outside_model_name = \"Van Gogh Diffusion\" #@param {type:\"string\"}\n",
        "model_file_name = \"Van\" #@param {type:\"string\"}\n",
        "baseline = \"SD 1.5\" # @param [\"SD 1.5\", \"SD XL\"]\n",
        "outside_model_download_url = \"https://huggingface.co/mirroring/horde_models/resolve/main/Van-Gogh-Diffusion.ckpt?download=true\" #@param {type:\"string\"}\n",
        "#@markdown ##### - To use unsupported/deprecated models (Segmind, Van Gogh Diffusion, etc)\n",
        "#@markdown ##### - For personal use, not to serve these models to the public\n",
        "#@markdown ##### - The worker is configured to activate Maintenance Mode when set to use outside models, this is to protect the owner\n",
        "#@markdown ##### - For this to work, all fields above must be filled:\n",
        "#@markdown ##### -1- outside_model, switch/toggle, a necessary check\n",
        "#@markdown ##### -2- outside_model_name, only for you to know what model is being served\n",
        "#@markdown ##### -3- model_file_name, the worker needs at least a part of the file's name to function\n",
        "#@markdown ##### -4- baseline, Stable Diffusion 1.5 or XL, necessary\n",
        "#@markdown ##### -4- outside_model_download_url, the download URL for the model you want to use. With civitai, check under \"1-2-3-x file\" and copy the download link there\n",
        "\n",
        "if(\"PickleTensor\" in outside_model_download_url or \".ckpt\" in outside_model_download_url):\n",
        "    file_extension = \".ckpt\"\n",
        "if(\"SafeTensor\" in outside_model_download_url or \".safetensors\" in outside_model_download_url):\n",
        "    file_extension = \".safetensors\"\n",
        "\n",
        "civitai = \"civitai.com/api/download/models\"\n",
        "if (civitai in outside_model_download_url):\n",
        "    outside_model_download_url = outside_model_download_url.split(\"?\")[0] + \"?token=\" + civitai_token\n",
        "\n",
        "new_mod15_ckpt = {\n",
        "    'model_name': \"Anything Diffusion\",\n",
        "    'file_name': \"Anything-Diffusion.ckpt\",\n",
        "    'sha256': \"633c153d96230355efb4230da6ae2e3ba85b084b93c89eb88cb1118d6cc06cef *Anything-Diffusion.sha256\",\n",
        "    'sha_name': \"Anything-Diffusion.sha256\"\n",
        "}\n",
        "new_mod15_safe = {\n",
        "    'model_name': \"Dreamshaper\",\n",
        "    'file_name': \"Dreamshaper.safetensors\",\n",
        "    'sha256': \"879db523c30d3b9017143d56705015e15a2cb5628762c11d086fed9538abd7fd *Dreamshaper.sha256\",\n",
        "    'sha_name': \"Dreamshaper.sha256\"\n",
        "}\n",
        "new_modxl_safe = {\n",
        "    'model_name': \"AlbedoBase XL (SDXL)\",\n",
        "    'file_name': \"albedo_base_xl.safetensors\",\n",
        "    'sha256': \"1718B5BB2DA1EF4815FEE8AF8A7FC2FA8AB8F467B279EDED4D991EA0CCE59A6D *albedo_base_xl.sha256\",\n",
        "    'sha_name': \"albedo_base_xl.sha256\"\n",
        "}\n",
        "if (baseline == \"SD XL\"):\n",
        "    new_mod = new_modxl_safe\n",
        "if (baseline == \"SD 1.5\"):\n",
        "    if(file_extension == \".ckpt\"):\n",
        "        new_mod = new_mod15_ckpt\n",
        "    if(file_extension == \".safetensors\"):\n",
        "        new_mod = new_mod15_safe\n",
        "\n",
        "if (outside_model and outside_model_name and outside_model_download_url):\n",
        "    selected_models = []\n",
        "    selected_models.append(new_mod['model_name'])\n",
        "    print (\"Running model not supported by the Horde (non-Customizer Role)\")\n",
        "    print (f'''Model: {outside_model_name:}, Horde Model: {new_mod['model_name']}, format: {new_mod['file_name'].split(\".\")[1]}''')\n",
        "# To actually enable models not supported by the Horde\n",
        "\n",
        "\n",
        "\n",
        "models_to_load = list(set(selected_models))\n",
        "print(f'Running: {models_to_load}')\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "allow_img2img = True #@param {type:\"boolean\"}\n",
        "allow_painting = True #@param {type:\"boolean\"}\n",
        "allow_lora = True #@param {type:\"boolean\"}\n",
        "allow_controlnet = False #@param {type:\"boolean\"}\n",
        "allow_post_processing = False #@param {type:\"boolean\"}\n",
        "#@markdown  ### I recommend you don't change these next 2 settings if you have no idea what you are doing\n",
        "queue_size = \"1\" # @param [0, 1, 2, 3, 4, 5]\n",
        "max_threads = \"1\" # @param [1, 2, 3]\n",
        "max_batch = \"5\" # @param [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "#@markdown ---\n",
        "\n",
        "safety_on_gpu = True\n",
        "nsfw = True\n",
        "censor_nsfw = False\n",
        "\n",
        "##############################\n",
        "#@markdown ## OPTIONAL, enabled by default\n",
        "#@markdown Disable default loras (reason: they are both obsolete and outdated)\n",
        "edit_lora_py_change_default_loras_bool = True #@param {type:\"boolean\"}\n",
        "#@markdown Increase Lora size limit to 1GB (reason: good donwload speed and storage capacity)\n",
        "edit_lora_py_increase_lora_size_limit_bool = True #@param {type:\"boolean\"}\n",
        "\n",
        "#markdown ## HIGHLY EXPERIMENTAL - OPTIONAL, disabled by default ####\n",
        "#markdown ##### Colab exclusive, for now, inject loras and textual inversions through prompt so they can be used in similar fashion to A1111\n",
        "#markdown ##### For loras: <lora:civitaiID or name:lora_strength:lora_clip:is_version, Anything you want here, to identify this lora>\n",
        "#markdown ##### Explaining is_version: 1--->True, 0--->False; If 0, use as always, put the civitAI ID and done; If 1, then you need the modelVersion (found in the URL on civitAI) instead of civitAI ID\n",
        "#markdown ##### Example with Add more details lora: \"<lora:82098:0.4:1.0:0, Add More Details>\": \"82098\", civitaiID; \"0.4\", lora model strength; \"1.0\", lora clip Strength; \"0\", is_version (0 means False);\n",
        "#markdown ##### For textual inversions: (embedding:civitaiID:ti_strength)\n",
        "#experimental = False #@param {type:\"boolean\"}\n",
        "#markdown ##### why? because some front-ends don't support loras/tis, so instead we let the worker handle that part and now EVERYONE can use them,\n",
        "#markdown ##### no matter what client they use to access the horde\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#markdown #### Obsolete while I set it up.\n",
        "beta_switch = False\n",
        "#markdown #### (RECOMMENDED) Enable this one to use the last stable version of the worker confirmed to work.\n",
        "#markdown #### IMPORTANT - If neither switch is set, it will download the current worker\n",
        "last_tested = False\n",
        "#markdown #### The maximum number of jobs the worker can do in a batch. I can confirm that up to 5 works, but there are very few batch requests for now so I don't yet know the best value for this.\n",
        "#markdown #### \"The horde will not give your max_batch at your max resolution, in order to avoid running out of VRAM. The Horde will assume you can fulfil your max batch at HALF your max resolution\"\n",
        "#markdown ---\n",
        "\n",
        "####For right now, THESE are the only variables that we care about\n",
        "\n",
        "\n",
        "horde_url = \"https://aihorde.net\"\n",
        "dynamic_models = False\n",
        "models_to_skip = [\"stable_diffusion_inpainting\", \"stable_diffusion_2.1\",  \"stable_diffusion_2.0\"]\n",
        "\n",
        "priority_usernames = []\n",
        "blacklist = []\n",
        "censorlist = []\n",
        "\n",
        "allow_unsafe_ip = True\n",
        "number_of_dynamic_models = 0\n",
        "max_models_to_download = 10\n",
        "forms = [\"caption\",\"nsfw\",\"interrogation\",\"post-process\"]\n",
        "\n",
        "\n",
        "current_path = \"/content/\"\n",
        "worker_path = current_path + \"horde-worker-reGen/\"\n",
        "bridgeData_file = worker_path + \"bridgeData.yaml\"\n",
        "notebook_version = \"23-05-2024\"\n",
        "\n",
        "#@markdown To reduce the level of verbosity/show shorter logs (Colab uses more and more of your PC RAM as the logs grow longer, but this will help with that)\n",
        "Short_Logs = False #@param {type:\"boolean\"}\n",
        "shorter_logs = Short_Logs\n",
        "#@markdown You can set here how often to clear logs (output only), in seconds. If left empty, logs will not be cleared\n",
        "interval = \"120\" #@param [\"\", 20, 30, 60, 120, 300, 1800, 3600]\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown To set maintenance mode ON/OFF on rerunning.\n",
        "Maintenance_Mode = False # @param {type:\"boolean\"}\n",
        "#@markdown Will be set to ON if running Outside Models. You need to keep your worker in Maintenance Mode with models not supported by the Horde, otherwise your worker will take people's request as normal and someone WILL report your worker for not giving the expected results.\n",
        "\n",
        "if not os.path.exists(bridgeData_file):\n",
        "    print (\"bridgeData.yaml file not found. Proceed to install the worker.\")\n",
        "else:\n",
        "    print (\"bridgeData.yaml file found. Recreating bridgeData.yaml and restarting the worker.\")\n",
        "    create_yaml()\n",
        "\n",
        "    download_models_aria2c()\n",
        "\n",
        "    if (Maintenance_Mode):\n",
        "        Maintenance_Mode = True\n",
        "    else:\n",
        "        if (outside_model and outside_model_name and outside_model_download_url):\n",
        "            Maintenance_Mode = True\n",
        "        else:\n",
        "            Maintenance_Mode = False\n",
        "    Set_Maintenance_Mode_function(Maintenance_Mode)\n",
        "\n",
        "    !cd /content\n",
        "    !source ../regen/bin/activate;python download_models.py\n",
        "    !cd /content\n",
        "\n",
        "    # Stop any reamining threads, maybe\n",
        "    stop_thread = True\n",
        "    # Start the thread\n",
        "    stop_thread = False\n",
        "    try:\n",
        "        threading.Thread(target=clear_output_periodically, args=(int(interval),)).start()\n",
        "        print(f\"Logs (output only) will be cleared every {int(interval)} seconds\")\n",
        "    except:\n",
        "        print(\"Logs will not be deleted\")\n",
        "\n",
        "    if (Short_Logs):\n",
        "        !source ../regen/bin/activate;python run_worker.py -vv\n",
        "    else:\n",
        "        !source ../regen/bin/activate;python run_worker.py\n",
        "\n",
        "# Stop any reamining threads, maybe\n",
        "stop_thread = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xluSRYFPRgy-",
        "outputId": "ce36c8ee-3e53-4f9b-f449-ed016c6470c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No worker with the name: mkrussell411, can't change Maintenance Mode. A new worker will be created with that name.\n"
          ]
        }
      ],
      "source": [
        "# @title Get the Worker OUT of Maintenance Mode { display-mode: \"form\" }\n",
        "# This cell is to get the worker out of maintenance before starting, since some people don't know how or where to do it\n",
        "# Should be alright to do it here since most errors for Colab workers are not the owner's fault\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "\n",
        "def Set_Maintenance_Mode_function(Maintenance_Mode):\n",
        "\n",
        "    i = False #Worker does not match/exist flag\n",
        "\n",
        "    command_find_user = f'''curl -X 'GET' \\\n",
        "              '{horde_url}/api/v2/find_user' \\\n",
        "              -H 'accept: application/json' \\\n",
        "              -H 'apikey: {api_key}' \\\n",
        "              -H 'Client-Agent: unknown:0:unknown'\n",
        "            '''\n",
        "\n",
        "    find_user_response = subprocess.check_output(command_find_user, shell=True).decode('utf-8')\n",
        "    data_api_key = json.loads(find_user_response)\n",
        "\n",
        "    if not (\"message\" in find_user_response):\n",
        "        for worker_id in data_api_key['worker_ids']:\n",
        "            command_find_worker = f'''curl -X 'GET' \\\n",
        "                      '{horde_url}/api/v2/workers/{worker_id}' \\\n",
        "                      -H 'accept: application/json' \\\n",
        "                      -H 'apikey: {api_key}' \\\n",
        "                      -H 'Client-Agent: unknown:0:unknown'\n",
        "                    '''\n",
        "            find_worker_response = subprocess.check_output(command_find_worker, shell=True).decode('utf-8')\n",
        "            data_worker = json.loads(find_worker_response)\n",
        "            if (worker_name == data_worker['name']):\n",
        "                print(f'''Worker name: {worker_name}, Worker ID: {worker_id}''')\n",
        "                i = True\n",
        "                if (Maintenance_Mode):\n",
        "                  set_maintenance_mode = \"true\"\n",
        "                else:\n",
        "                  set_maintenance_mode = \"false\"\n",
        "                command_maintenance_mode = f'''curl -X 'PUT' \\\n",
        "                  '{horde_url}/api/v2/workers/{worker_id}' \\\n",
        "                  -H 'accept: application/json' \\\n",
        "                  -H 'apikey: {api_key}' \\\n",
        "                  -H 'Client-Agent: unknown:0:unknown' \\\n",
        "                  -H 'Content-Type: application/json' \\\n",
        "                  -d'''+ r''' '{\n",
        "                  \"maintenance\":''' + f''' {set_maintenance_mode}\n",
        "                ''' + r'''}'\n",
        "                '''\n",
        "                maintenance_mode_response = subprocess.check_output(command_maintenance_mode, shell=True).decode('utf-8')\n",
        "                print(maintenance_mode_response)\n",
        "        if not i:\n",
        "          print(f'''No worker with the name: {worker_name}, can't change Maintenance Mode. A new worker will be created with that name.''')\n",
        "          worker_id = 0\n",
        "    else:\n",
        "        print(f'''The API key \"{api_key}\" does not exist''')\n",
        "\n",
        "Maintenance_Mode = False\n",
        "Set_Maintenance_Mode_function(Maintenance_Mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cVecpjOM1xPu",
        "trusted": true,
        "outputId": "ed8cf260-0d55-4a98-fe87-44ea5b0c887a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10-venv is already the newest version (3.10.12-1~22.04.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Error: Command '['/content/regen/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "# @title 1.- Virtual Environment  { display-mode: \"form\" }\n",
        "\n",
        "!apt-get update\n",
        "!apt install python3.10-venv\n",
        "!python -m venv regen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZzwQDVd_1xPu",
        "trusted": true,
        "outputId": "6c1e4349-d564-467d-85a2-8c3222133329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'horde-worker-reGen': No such file or directory\n",
            "Horde Engine Line: horde_engine~=2.20.12\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 2.- Remove the worker if it exists, then, Clone the regen worker { display-mode: \"form\" }\n",
        "\n",
        "!cd /content;rm -r horde-worker-reGen\n",
        "\n",
        "if (beta_switch):\n",
        "    #!cd /content;git clone -b niter https://github.com/Haidra-Org/horde-worker-reGen.git > /dev/null 2>&1\n",
        "    ## Deleting the next part when beta_switch is ready, too lazy to figure it out\n",
        "    !cd /content;git clone https://github.com/Haidra-Org/horde-worker-reGen.git > /dev/null 2>&1\n",
        "    if (last_tested):\n",
        "        %cd /content/horde-worker-reGen\n",
        "        version = \"0776b3967d566ac3826a8c2083d0c315caaf26a1\"\n",
        "        !cd /content/horde-worker-reGen;git checkout version > /dev/null 2>&1\n",
        "        print (f'Worker Version (hash): {version}')\n",
        "        %cd /content\n",
        "else:\n",
        "    !cd /content;git clone https://github.com/Haidra-Org/horde-worker-reGen.git > /dev/null 2>&1\n",
        "    if (last_tested):\n",
        "        %cd /content/horde-worker-reGen\n",
        "        version = \"0776b3967d566ac3826a8c2083d0c315caaf26a1\"\n",
        "        !cd /content/horde-worker-reGen;git checkout version > /dev/null 2>&1\n",
        "        print (f'Worker Version (hash): {version}')\n",
        "        %cd /content\n",
        "\n",
        "# Necessary for edits, etc\n",
        "requirements_path = \"/content/horde-worker-reGen/requirements.txt\"\n",
        "horde_engine_version = \"fail\"\n",
        "# read the file\n",
        "with open(requirements_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "found_line_number = -1\n",
        "search_horde_engine_version = \"horde_engine\"\n",
        "for i, line in enumerate(lines):\n",
        "    if search_horde_engine_version in line:\n",
        "        horde_engine_version = line\n",
        "        break\n",
        "\n",
        "if (\"fail\" in horde_engine_version):\n",
        "    print (\"Could not find hordelib version in requirements.txt\")\n",
        "\n",
        "import re\n",
        "horde_engine_version_numeric_part = re.sub(r'^\\D*', '', horde_engine_version).rstrip()\n",
        "print (f'Horde Engine Line: {horde_engine_version}')\n",
        "horde_engine_version = horde_engine_version_numeric_part\n",
        "horde_engine_url = \"https://raw.githubusercontent.com/Haidra-Org/hordelib/v\" + horde_engine_version + \"/hordelib/\"\n",
        "horde_engine_path = \"/content/regen/lib/python3.10/site-packages/hordelib/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC4lce-51xPv",
        "scrolled": true,
        "trusted": true,
        "outputId": "372f2751-7ab1-4f03-fa56-f9d0912a716f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: regen/bin/activate: No such file or directory\n",
            "Collecting torch==2.5.0 (from -r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting qrcode==7.4.2 (from -r ./horde-worker-reGen/requirements.txt (line 2))\n",
            "  Downloading qrcode-7.4.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from -r ./horde-worker-reGen/requirements.txt (line 4)) (2025.1.31)\n",
            "Collecting horde_sdk~=0.17.1 (from -r ./horde-worker-reGen/requirements.txt (line 6))\n",
            "  Downloading horde_sdk-0.17.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_safety~=0.2.3 (from -r ./horde-worker-reGen/requirements.txt (line 7))\n",
            "  Downloading horde_safety-0.2.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_engine~=2.20.12 (from -r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading horde_engine-2.20.12-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_model_reference>=0.9.2 (from -r ./horde-worker-reGen/requirements.txt (line 9))\n",
            "  Downloading horde_model_reference-0.9.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from -r ./horde-worker-reGen/requirements.txt (line 11))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel.yaml (from -r ./horde-worker-reGen/requirements.txt (line 12))\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting semver (from -r ./horde-worker-reGen/requirements.txt (line 13))\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from -r ./horde-worker-reGen/requirements.txt (line 14)) (0.45.1)\n",
            "Collecting python-Levenshtein (from -r ./horde-worker-reGen/requirements.txt (line 16))\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from -r ./horde-worker-reGen/requirements.txt (line 18)) (2.10.6)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from -r ./horde-worker-reGen/requirements.txt (line 19)) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r ./horde-worker-reGen/requirements.txt (line 20)) (2.32.3)\n",
            "Collecting StrEnum (from -r ./horde-worker-reGen/requirements.txt (line 21))\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting loguru (from -r ./horde-worker-reGen/requirements.txt (line 22))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (from -r ./horde-worker-reGen/requirements.txt (line 24)) (2.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (1.13.1)\n",
            "Collecting pypng (from qrcode==7.4.2->-r ./horde-worker-reGen/requirements.txt (line 2))\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (1.3.0)\n",
            "Collecting pydantic>=2.9.2 (from -r ./horde-worker-reGen/requirements.txt (line 18))\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (3.11.12)\n",
            "Collecting aiofiles (from horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiodns (from horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6))\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (11.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->-r ./horde-worker-reGen/requirements.txt (line 18)) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic>=2.9.2->-r ./horde-worker-reGen/requirements.txt (line 18))\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting clip-interrogator==0.6.0 (from horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7))\n",
            "  Downloading clip_interrogator-0.6.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting unidecode (from horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7))\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7)) (0.20.1+cu124)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7)) (0.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7)) (4.67.1)\n",
            "Collecting open-clip-torch (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7))\n",
            "  Downloading open_clip_torch-2.30.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: transformers>=4.27.1 in /usr/local/lib/python3.11/dist-packages (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7)) (4.48.3)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.26.4)\n",
            "Collecting torchdiffeq (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.2.0)\n",
            "Collecting pytorch_lightning (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pynvml (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (3.1.44)\n",
            "Collecting clip-anytorch (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: diffusers>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.32.2)\n",
            "Collecting omegaconf (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.9.0)\n",
            "Collecting rembg[cpu] (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading rembg-2.0.62-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.11.0.86)\n",
            "Collecting timm==0.9.16 (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.13.1)\n",
            "Collecting addict (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fairscale (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.25.1)\n",
            "Collecting mediapipe>=0.9.1.0 (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting fuzzywuzzy (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting kornia (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting spandrel (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting spandrel_extra_arches (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading spandrel_extra_arches-0.2.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting lpips (from horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.28.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->-r ./horde-worker-reGen/requirements.txt (line 12))\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-Levenshtein->-r ./horde-worker-reGen/requirements.txt (line 16))\n",
            "  Downloading levenshtein-0.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein->-r ./horde-worker-reGen/requirements.txt (line 16))\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r ./horde-worker-reGen/requirements.txt (line 20)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r ./horde-worker-reGen/requirements.txt (line 20)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r ./horde-worker-reGen/requirements.txt (line 20)) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.25.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (8.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.25.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (2024.11.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (25.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.25.6)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.27.1->clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7)) (24.2)\n",
            "Collecting pycares>=4.0.0 (from aiodns->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6))\n",
            "  Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (1.18.3)\n",
            "Collecting ftfy (from clip-anytorch->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0->-r ./horde-worker-reGen/requirements.txt (line 1)) (3.0.2)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from clip-interrogator==0.6.0->horde_safety~=0.2.3->-r ./horde-worker-reGen/requirements.txt (line 7))\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.23.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.8.2)\n",
            "Collecting pymatting (from rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting onnxruntime (from rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (2025.1.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.4)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (5.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (75.1.0)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pycares>=4.0.0->aiodns->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (1.17.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip-anytorch->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers>=0.25.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (3.21.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.22.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (2.8.2)\n",
            "Collecting coloredlogs (from onnxruntime->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (4.3.6)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.61.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->horde_sdk~=0.17.1->-r ./horde-worker-reGen/requirements.txt (line 6)) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (0.44.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe>=0.9.1.0->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8)) (1.17.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->rembg[cpu]->horde_engine~=2.20.12->-r ./horde-worker-reGen/requirements.txt (line 8))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/127.9 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title 3.- Install requirements { display-mode: \"form\" }\n",
        "\n",
        "!source regen/bin/activate;pip install -r .\\/horde-worker-reGen/requirements.txt\n",
        "\n",
        "# Fix for cuda 11.8 no longer required\n",
        "#!source regen/bin/activate;pip install -r .\\/horde-worker-reGen/requirements.118.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-I1XNxx1xPv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# @title 4.- Create .yaml config file { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "\n",
        "%cd $worker_path\n",
        "print (\"Creating bridgeData.yaml file.\")\n",
        "\n",
        "def create_yaml():\n",
        "\n",
        "    from yaml import load, dump\n",
        "\n",
        "    def make_yaml_sublist(list_to_convert: list[str]):\n",
        "        sublist_yaml = dump(list_to_convert)\n",
        "        sublist_yaml = \"\\n\" + sublist_yaml\n",
        "        return sublist_yaml\n",
        "\n",
        "\n",
        "\n",
        "    data = f\"\"\"horde_url: \"{horde_url}\"\n",
        "api_key: \"{api_key}\"\n",
        "civitai_api_token: \"{civitai_token}\"\n",
        "priority_usernames: []\n",
        "max_threads: {max_threads}\n",
        "queue_size: {queue_size}\n",
        "max_batch: {max_batch}\n",
        "safety_on_gpu: {safety_on_gpu}\n",
        "require_upfront_kudos: false\n",
        "cycle_process_on_model_change: true\n",
        "dreamer_name: \"{worker_name}\"\n",
        "max_power: {max_power}\n",
        "nsfw: {nsfw.__str__().lower()}\n",
        "censor_nsfw: {censor_nsfw}\n",
        "blacklist: {blacklist}\n",
        "censorlist: {censorlist}\n",
        "allow_img2img: {allow_img2img.__str__().lower()}\n",
        "allow_painting: {allow_painting.__str__().lower()}\n",
        "allow_unsafe_ip: true\n",
        "allow_post_processing: {allow_post_processing.__str__().lower()}\n",
        "allow_controlnet: {allow_controlnet.__str__().lower()}\n",
        "allow_lora: {allow_lora.__str__().lower()}\n",
        "max_lora_cache_size: 20\n",
        "dynamic_models: false\n",
        "number_of_dynamic_models: 0\n",
        "max_models_to_download: 10\n",
        "stats_output_frequency: 30\n",
        "cache_home: \"./\"\n",
        "always_download: true\n",
        "temp_dir: \"./tmp\"\n",
        "disable_terminal_ui: True\n",
        "vram_to_leave_free: \"80%\"\n",
        "ram_to_leave_free: \"80%\"\n",
        "disable_disk_cache: false\n",
        "models_to_load: {make_yaml_sublist(models_to_load)}\n",
        "models_to_skip: {make_yaml_sublist(models_to_skip)}\n",
        "suppress_speed_warnings: false\n",
        "forms:\n",
        "- \"caption\"\n",
        "- \"nsfw\"\n",
        "- \"interrogation\"\n",
        "- \"post-process\"\n",
        "\"\"\"\n",
        "\n",
        "    with open(bridgeData_file, \"w\") as text_file:\n",
        "        text_file.write(data)\n",
        "\n",
        "    print (\"bridgeData.yaml file created.\")\n",
        "\n",
        "create_yaml()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4_3X8iIRgzD"
      },
      "outputs": [],
      "source": [
        "# @title Download models using aria2c { display-mode: \"form\" }\n",
        "\n",
        "model_reference = \"/content/stable_diffusion.json\"\n",
        "\n",
        "# create compvis folder\n",
        "!mkdir -p /content/horde-worker-reGen/compvis\n",
        "\n",
        "# download the model reference if necessary\n",
        "import os\n",
        "if os.path.exists(model_reference):\n",
        "    print(\"Model Reference exists.\")\n",
        "else:\n",
        "    print(\"Downloading Model Reference.\")\n",
        "    !wget https://raw.githubusercontent.com/Haidra-Org/AI-Horde-image-model-reference/main/stable_diffusion.json -O /content/stable_diffusion.json\n",
        "\n",
        "# install aria2c if necessary\n",
        "import subprocess\n",
        "try:\n",
        "    # Run the command\n",
        "    output = subprocess.check_output([\"which\", \"aria2c\"])\n",
        "    # unnecessary to do this next step, but whatever, I can use the output from above with this\n",
        "    output = output.decode(\"utf-8\")\n",
        "    print(\"aria2c is installed.\")\n",
        "except:\n",
        "    print(f\"Installing aria2c.\")\n",
        "    !apt-get install -y aria2\n",
        "\n",
        "\n",
        "# function to look in the model reference for the selected models\n",
        "import json\n",
        "def find_matching_entries(filename, key, value_list):\n",
        "    \"\"\"\n",
        "    Finds all entries in a JSON file that match a given key and value list.\n",
        "\n",
        "    Args:\n",
        "      filename: The path to the JSON file.\n",
        "      key: The key to search for.\n",
        "      value_list: A list of values to match.\n",
        "\n",
        "    Returns:\n",
        "      A list of entries that match the criteria.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    matching_entries = []\n",
        "    for entry in data.items():\n",
        "        #print(entry)\n",
        "        if entry[0] in value_list:\n",
        "            matching_entries.append(entry)\n",
        "\n",
        "    return matching_entries\n",
        "\n",
        "\n",
        "# function to download the models with aria2c\n",
        "def download_models_aria2c():\n",
        "\n",
        "    filename = model_reference\n",
        "    key = \"name\"\n",
        "    value_list = selected_models\n",
        "    # call the find function\n",
        "    matching_entries = find_matching_entries(filename, key, value_list)\n",
        "\n",
        "    # download the model(s) and create the hash file(s)\n",
        "    %cd $worker_path\n",
        "    for entry in matching_entries:\n",
        "        #download link\n",
        "        if (\"civitai\" in entry[1][\"config\"]['download'][0]['file_url']):\n",
        "            entry[1][\"config\"]['download'][0]['file_url'] = entry[1][\"config\"]['download'][0]['file_url'].split(\"?\")[0] + \"?token=\" + civitai_token\n",
        "        if (outside_model and outside_model_name and outside_model_download_url and entry[0] in mask['model_name']):\n",
        "            print(f\"Outside model:{outside_model_name}\")\n",
        "            download_link = outside_model_download_url\n",
        "        else:\n",
        "            download_link = entry[1][\"config\"]['download'][0]['file_url']\n",
        "        print(download_link)\n",
        "        # file name\n",
        "        file_name = entry[1][\"config\"]['download'][0]['file_name']\n",
        "        print(file_name)\n",
        "        file_path = \"compvis/\" + file_name\n",
        "        # sha256\n",
        "        sha_name = file_name.split(\".\")[0] + \".sha256\"\n",
        "        sha = entry[1][\"config\"]['files'][0]['sha256sum']\n",
        "        sha = sha + \" *\" + sha_name\n",
        "        sha_path = \"/content/horde-worker-reGen/compvis/\" + sha_name\n",
        "        print(sha)\n",
        "        # donwnload model and create sha file\n",
        "        !aria2c -c -x 16 -s 16 -p $download_link -o $file_path\n",
        "        !rm $sha_path\n",
        "        !echo {sha} > $sha_path\n",
        "\n",
        "download_models_aria2c()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4T6RA-xRgzE"
      },
      "outputs": [],
      "source": [
        "# @title ## Function: download file(s) { display-mode: \"form\" }\n",
        "\n",
        "# Simple download function with wget\n",
        "def download_file_wget(install_path, download_url):\n",
        "    !wget -O {install_path} {download_url}\n",
        "\n",
        "\n",
        "# define names, paths and urls for the files to download\n",
        "\n",
        "# horde engine files\n",
        "model_manager_folder = \"model_manager/\"\n",
        "name_lora_py = \"lora.py\"\n",
        "url_lora_py = horde_engine_url + model_manager_folder + name_lora_py\n",
        "path_lora_py = horde_engine_path + model_manager_folder + name_lora_py\n",
        "\n",
        "def download_files():\n",
        "    if (download_lora_py_bool):\n",
        "        download_file_wget(install_path = path_lora_py, download_url = url_lora_py)\n",
        "\n",
        "# Use the switches/toggles to download the file(s) as necessary\n",
        "#@markdown Only to download again the files affected by the edits, effectively reverting any changes made to them. Only for emergencies or if you know what you are doing\n",
        "download_lora_py_bool = False #@param {type:\"boolean\"}\n",
        "\n",
        "download_files()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5EbnADnRgzE"
      },
      "outputs": [],
      "source": [
        "# @title ## Function: edit file(s) { display-mode: \"form\" }\n",
        "def Edit_file_code(goal, target_file, target_code, new_code, lines_offset, pop_x_lines):\n",
        "\n",
        "    print(f'''-------------------------------------\n",
        "Purpose: {goal}\n",
        "target file: {target_file}\n",
        "target code:\\n{target_code}\n",
        "new code:\\n{new_code}\n",
        "lines offset: {lines_offset}\n",
        "{pop_x_lines} lines to pop''')\n",
        "\n",
        "    # check if the edit was already done, exit if so\n",
        "    with open(target_file, 'r') as file:\n",
        "        data = file.read()\n",
        "    if (new_code in data):\n",
        "        print (f'''The new code was found in target file: {target_file}. The edit was already done. Exiting.''')\n",
        "        return\n",
        "\n",
        "    # read the file\n",
        "    with open(target_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    found_line_number = -1\n",
        "\n",
        "    # find the target line \"target_code\"\n",
        "    for i, line in enumerate(lines):\n",
        "        if target_code in line:\n",
        "            found_line_number = i\n",
        "            break\n",
        "\n",
        "    # it should always find it, but whatever, insert \"new_code\" to the data\n",
        "    if found_line_number != -1:\n",
        "        if (pop_x_lines):\n",
        "            print (\"haa\")\n",
        "            for i in range(pop_x_lines):\n",
        "                lines.pop(found_line_number)\n",
        "        lines.insert(found_line_number + lines_offset, new_code)\n",
        "        print (f'''New code added to target file: {target_file}. File edited.''')\n",
        "    else:\n",
        "        print (f'''Could not find target code: {target_code}.''')\n",
        "\n",
        "    # rewrite target_file\n",
        "    with open(target_file, 'w') as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "\n",
        "# Changes/edits to the worker\n",
        "\"\"\"\n",
        "    Change default loras, ignore the long, useless, outdated, deprecated list\n",
        "\"\"\"\n",
        "def edit_lora_py_change_default_loras():\n",
        "    # variables\n",
        "    goal = \"Change default Loras list for mine\"\n",
        "    target_file = path_lora_py\n",
        "    target_code = '''            self._default_lora_ids = self._get_json(self.LORA_DEFAULTS)'''\n",
        "    new_code = r'''            self._default_lora_ids = [216620, 216590]\n",
        "'''\n",
        "    lines_offset = 0\n",
        "    pop_x_lines = 1\n",
        "    # call the edit file function\n",
        "    Edit_file_code(goal, target_file, target_code, new_code, lines_offset, pop_x_lines)\n",
        "\n",
        "\"\"\"\n",
        "    Increase Lora size limit to 1GB\n",
        "\"\"\"\n",
        "def edit_lora_py_increase_lora_size_limit():\n",
        "    # variables\n",
        "    goal = \"Increase Lora size limit to 1GB\"\n",
        "    target_file = path_lora_py\n",
        "    target_code = '''            and lora[\"versions\"][lora_version][\"size_mb\"] > 220'''\n",
        "    new_code = r'''            and lora[\"versions\"][lora_version][\"size_mb\"] > 1024\n",
        "'''\n",
        "    lines_offset = 0\n",
        "    pop_x_lines = 1\n",
        "    # call the edit file function\n",
        "    Edit_file_code(goal, target_file, target_code, new_code, lines_offset, pop_x_lines)\n",
        "\n",
        "\n",
        "# Execute all enabled edits\n",
        "def edit_files():\n",
        "    if (edit_lora_py_change_default_loras_bool):\n",
        "        edit_lora_py_change_default_loras()\n",
        "    if (edit_lora_py_increase_lora_size_limit_bool):\n",
        "        edit_lora_py_increase_lora_size_limit()\n",
        "\n",
        "edit_files()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwMyg3JN1xPv",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# @title 6.- Run download models { display-mode: \"form\" }\n",
        "\n",
        "# Make sure you have the correct path based on any `cd` commands above\n",
        "!cd /content\n",
        "\n",
        "!source ../regen/bin/activate;python download_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRnzqILb1xPw",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# @title 7.- Run the worker { display-mode: \"form\" }\n",
        "\n",
        "# Make sure you have the correct path based on any `cd` commands above\n",
        "!cd /content\n",
        "\n",
        "if (outside_model and outside_model_name and outside_model_download_url):\n",
        "    Maintenance_Mode = True\n",
        "Set_Maintenance_Mode_function(Maintenance_Mode)\n",
        "\n",
        "# Stop any reamining threads, maybe\n",
        "stop_thread = True\n",
        "# Start the thread\n",
        "stop_thread = False\n",
        "# To periodically clear the logs\n",
        "# @markdown If this interval is changed to anything other than \"ignore\", it will override the value set on the first cell\n",
        "interval2 = \"ignore\" #@param [\"ignore\", \"\", 20, 30, 60, 120, 300, 1800, 3600]\n",
        "if (\"ignore\" in interval2):\n",
        "    try:\n",
        "        threading.Thread(target=clear_output_periodically, args=(int(interval),)).start()\n",
        "        print(f\"Logs (output only) will be cleared every {int(interval)} seconds\")\n",
        "    except:\n",
        "        print(\"Logs will not be deleted\")\n",
        "else:\n",
        "    try:\n",
        "        threading.Thread(target=clear_output_periodically, args=(int(interval2),)).start()\n",
        "        print(f\"Logs (output only) will be cleared every {int(interval2)} seconds\")\n",
        "    except:\n",
        "        print(\"Logs will not be deleted\")\n",
        "\n",
        "\n",
        "if (shorter_logs):\n",
        "    !source ../regen/bin/activate;python run_worker.py -vv\n",
        "else:\n",
        "    !source ../regen/bin/activate;python run_worker.py\n",
        "\n",
        "# Stop the thread when the cell is stopped.\n",
        "stop_thread = True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}